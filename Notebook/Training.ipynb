{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1fd74e-a2a7-44ad-a7c3-478665dcd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/src')\n",
    "from easter_model import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83a8f00-1d9b-48a9-ba17-956ca8ce2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiend\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intializing from checkpoint :  C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2\\weights\\saved_weights.weights.h5\n",
      "Init weights loaded successfully....\n",
      "loading metdata...\n",
      "Training Samples :  6482\n",
      "Validation Samples :  976\n",
      "Test Samples :  2915\n",
      "CharList Size :  79\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 2000, 80)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1000, 128)    30848       ['the_input[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1000, 128)   512         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1000, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1000, 128)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 500, 128)     49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500, 128)    512         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500, 128)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 500, 128)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 500, 256)     164096      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 500, 256)    1024        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500, 256)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 500, 256)     0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 500, 256)     327936      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 500, 256)    1024        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 500, 256)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 500, 256)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 500, 256)     327936      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 500, 256)    1024        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 256)         0           ['batch_normalization_6[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           8224        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500, 256)    1024        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 500, 256)    1024        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          8448        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 500, 256)     0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 500, 256)     0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 500, 256)     0           ['add[0][0]',                    \n",
      "                                                                  'multiply[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 500, 256)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 500, 256)     0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 500, 256)     459008      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 500, 256)    1024        ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 500, 256)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 500, 256)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 500, 256)     459008      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 500, 256)    1024        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 500, 256)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 500, 256)     0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 500, 256)     459008      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 500, 256)    1024        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 256)         0           ['batch_normalization_11[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 500, 256)     65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 500, 256)     65792       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8224        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 500, 256)    1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 500, 256)    1024        ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          8448        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 500, 256)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 500, 256)     0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 500, 256)     0           ['add_2[0][0]',                  \n",
      "                                                                  'multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 500, 256)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 500, 256)     0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 500, 256)     590080      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 500, 256)    1024        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 500, 256)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 500, 256)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 500, 256)     590080      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 500, 256)    1024        ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 500, 256)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 500, 256)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 500, 256)     590080      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 500, 256)    1024        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 256)         0           ['batch_normalization_16[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 500, 256)     65792       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 500, 256)     65792       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           8224        ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 500, 256)    1024        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 500, 256)    1024        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          8448        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 500, 256)     0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 500, 256)     0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 500, 256)     0           ['add_4[0][0]',                  \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 500, 256)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 500, 256)     0           ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 500, 512)     1442304     ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 500, 512)    2048        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 500, 512)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 500, 512)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 500, 512)     262656      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 512)    2048        ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 500, 512)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 500, 512)     0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 500, 80)      41040       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " Final (Activation)             (None, 500, 80)      0           ['conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['Final[0][0]',                  \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,193,072\n",
      "Trainable params: 6,182,832\n",
      "Non-trainable params: 10,240\n",
      "__________________________________________________________________________________________________\n",
      "Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiend\\OneDrive\\Documents\\ASU MSBA 2024\\CIS515 AI and Data Analytics Strategy\\Final Project\\Easter2\\src\\easter_model.py:290: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "202/202 [==============================] - 618s 3s/step - loss: 14.6283 - val_loss: 11.9687\n",
      "Epoch 2/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 14.5517\n",
      "Epoch 2: loss improved from inf to 14.55174, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--02--14.55.keras\n",
      "202/202 [==============================] - 634s 3s/step - loss: 14.5517 - val_loss: 11.7232\n",
      "Epoch 3/51\n",
      "202/202 [==============================] - 657s 3s/step - loss: 14.4804 - val_loss: 11.8719\n",
      "Epoch 4/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 14.2531\n",
      "Epoch 4: loss improved from 14.55174 to 14.25310, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--04--14.25.keras\n",
      "202/202 [==============================] - 669s 3s/step - loss: 14.2531 - val_loss: 11.7244\n",
      "Epoch 5/51\n",
      "202/202 [==============================] - 660s 3s/step - loss: 14.2364 - val_loss: 11.4957\n",
      "Epoch 6/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 14.2476\n",
      "Epoch 6: loss improved from 14.25310 to 14.24759, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--06--14.25.keras\n",
      "202/202 [==============================] - 661s 3s/step - loss: 14.2476 - val_loss: 11.3960\n",
      "Epoch 7/51\n",
      "202/202 [==============================] - 644s 3s/step - loss: 14.0699 - val_loss: 11.2783\n",
      "Epoch 8/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 14.0553\n",
      "Epoch 8: loss improved from 14.24759 to 14.05528, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--08--14.06.keras\n",
      "202/202 [==============================] - 642s 3s/step - loss: 14.0553 - val_loss: 11.7061\n",
      "Epoch 9/51\n",
      "202/202 [==============================] - 645s 3s/step - loss: 13.9494 - val_loss: 11.4639\n",
      "Epoch 10/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 14.0987\n",
      "Epoch 10: loss did not improve from 14.05528\n",
      "202/202 [==============================] - 641s 3s/step - loss: 14.0987 - val_loss: 11.8226\n",
      "Epoch 11/51\n",
      "202/202 [==============================] - 640s 3s/step - loss: 13.6966 - val_loss: 11.3919\n",
      "Epoch 12/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.8207\n",
      "Epoch 12: loss improved from 14.05528 to 13.82072, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--12--13.82.keras\n",
      "202/202 [==============================] - 635s 3s/step - loss: 13.8207 - val_loss: 11.0921\n",
      "Epoch 13/51\n",
      "202/202 [==============================] - 640s 3s/step - loss: 13.8166 - val_loss: 11.2583\n",
      "Epoch 14/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.7743\n",
      "Epoch 14: loss improved from 13.82072 to 13.77434, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--14--13.77.keras\n",
      "202/202 [==============================] - 641s 3s/step - loss: 13.7743 - val_loss: 11.1275\n",
      "Epoch 15/51\n",
      "202/202 [==============================] - 642s 3s/step - loss: 13.6743 - val_loss: 11.4043\n",
      "Epoch 16/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.7218\n",
      "Epoch 16: loss improved from 13.77434 to 13.72177, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--16--13.72.keras\n",
      "202/202 [==============================] - 643s 3s/step - loss: 13.7218 - val_loss: 10.9097\n",
      "Epoch 17/51\n",
      "202/202 [==============================] - 642s 3s/step - loss: 13.5572 - val_loss: 11.2704\n",
      "Epoch 18/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.5689\n",
      "Epoch 18: loss improved from 13.72177 to 13.56892, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--18--13.57.keras\n",
      "202/202 [==============================] - 631s 3s/step - loss: 13.5689 - val_loss: 10.9357\n",
      "Epoch 19/51\n",
      "202/202 [==============================] - 632s 3s/step - loss: 13.5477 - val_loss: 10.9882\n",
      "Epoch 20/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.3967\n",
      "Epoch 20: loss improved from 13.56892 to 13.39672, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--20--13.40.keras\n",
      "202/202 [==============================] - 637s 3s/step - loss: 13.3967 - val_loss: 11.2379\n",
      "Epoch 21/51\n",
      "202/202 [==============================] - 641s 3s/step - loss: 13.4765 - val_loss: 11.0073\n",
      "Epoch 22/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.4532\n",
      "Epoch 22: loss did not improve from 13.39672\n",
      "202/202 [==============================] - 642s 3s/step - loss: 13.4532 - val_loss: 11.2934\n",
      "Epoch 23/51\n",
      "202/202 [==============================] - 643s 3s/step - loss: 13.2555 - val_loss: 11.0007\n",
      "Epoch 24/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.2473\n",
      "Epoch 24: loss improved from 13.39672 to 13.24731, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--24--13.25.keras\n",
      "202/202 [==============================] - 640s 3s/step - loss: 13.2473 - val_loss: 11.0162\n",
      "Epoch 25/51\n",
      "202/202 [==============================] - 643s 3s/step - loss: 13.4274 - val_loss: 11.2490\n",
      "Epoch 26/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.1716\n",
      "Epoch 26: loss improved from 13.24731 to 13.17162, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--26--13.17.keras\n",
      "202/202 [==============================] - 633s 3s/step - loss: 13.1716 - val_loss: 10.8441\n",
      "Epoch 27/51\n",
      "202/202 [==============================] - 626s 3s/step - loss: 13.1074 - val_loss: 11.2058\n",
      "Epoch 28/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.1206\n",
      "Epoch 28: loss improved from 13.17162 to 13.12065, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--28--13.12.keras\n",
      "202/202 [==============================] - 633s 3s/step - loss: 13.1206 - val_loss: 10.8144\n",
      "Epoch 29/51\n",
      "202/202 [==============================] - 634s 3s/step - loss: 13.0414 - val_loss: 10.8312\n",
      "Epoch 30/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.7071\n",
      "Epoch 30: loss did not improve from 13.12065\n",
      "202/202 [==============================] - 637s 3s/step - loss: 13.7071 - val_loss: 11.3819\n",
      "Epoch 31/51\n",
      "202/202 [==============================] - 641s 3s/step - loss: 13.1263 - val_loss: 10.5507\n",
      "Epoch 32/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.1807\n",
      "Epoch 32: loss did not improve from 13.12065\n",
      "202/202 [==============================] - 639s 3s/step - loss: 13.1807 - val_loss: 11.2133\n",
      "Epoch 33/51\n",
      "202/202 [==============================] - 641s 3s/step - loss: 12.9908 - val_loss: 10.5872\n",
      "Epoch 34/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.0312\n",
      "Epoch 34: loss improved from 13.12065 to 13.03120, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--34--13.03.keras\n",
      "202/202 [==============================] - 640s 3s/step - loss: 13.0312 - val_loss: 11.3898\n",
      "Epoch 35/51\n",
      "202/202 [==============================] - 640s 3s/step - loss: 12.9811 - val_loss: 10.5305\n",
      "Epoch 36/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.8949\n",
      "Epoch 36: loss improved from 13.03120 to 12.89489, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--36--12.89.keras\n",
      "202/202 [==============================] - 636s 3s/step - loss: 12.8949 - val_loss: 10.5086\n",
      "Epoch 37/51\n",
      "202/202 [==============================] - 626s 3s/step - loss: 12.7793 - val_loss: 10.9156\n",
      "Epoch 38/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.7299\n",
      "Epoch 38: loss improved from 12.89489 to 12.72989, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--38--12.73.keras\n",
      "202/202 [==============================] - 625s 3s/step - loss: 12.7299 - val_loss: 11.1752\n",
      "Epoch 39/51\n",
      "202/202 [==============================] - 632s 3s/step - loss: 12.5976 - val_loss: 10.5693\n",
      "Epoch 40/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.6804\n",
      "Epoch 40: loss improved from 12.72989 to 12.68043, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--40--12.68.keras\n",
      "202/202 [==============================] - 635s 3s/step - loss: 12.6804 - val_loss: 10.9656\n",
      "Epoch 41/51\n",
      "202/202 [==============================] - 632s 3s/step - loss: 12.6449 - val_loss: 10.4778\n",
      "Epoch 42/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.0262\n",
      "Epoch 42: loss did not improve from 12.68043\n",
      "202/202 [==============================] - 634s 3s/step - loss: 13.0262 - val_loss: 10.6135\n",
      "Epoch 43/51\n",
      "202/202 [==============================] - 646s 3s/step - loss: 12.5981 - val_loss: 10.2155\n",
      "Epoch 44/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.8254\n",
      "Epoch 44: loss did not improve from 12.68043\n",
      "202/202 [==============================] - 638s 3s/step - loss: 12.8254 - val_loss: 10.3554\n",
      "Epoch 45/51\n",
      "202/202 [==============================] - 633s 3s/step - loss: 12.5871 - val_loss: 10.7988\n",
      "Epoch 46/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.6352\n",
      "Epoch 46: loss improved from 12.68043 to 12.63519, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--46--12.64.keras\n",
      "202/202 [==============================] - 633s 3s/step - loss: 12.6352 - val_loss: 10.2708\n",
      "Epoch 47/51\n",
      "202/202 [==============================] - 635s 3s/step - loss: 12.5403 - val_loss: 10.5255\n",
      "Epoch 48/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.6977\n",
      "Epoch 48: loss did not improve from 12.63519\n",
      "202/202 [==============================] - 635s 3s/step - loss: 12.6977 - val_loss: 10.6123\n",
      "Epoch 49/51\n",
      "202/202 [==============================] - 637s 3s/step - loss: 12.6371 - val_loss: 10.5909\n",
      "Epoch 50/51\n",
      "202/202 [==============================] - ETA: 0s - loss: 12.6009\n",
      "Epoch 50: loss improved from 12.63519 to 12.60095, saving model to C:/Users/tiend/OneDrive/Documents/ASU MSBA 2024/CIS515 AI and Data Analytics Strategy/Final Project/Easter2/weights\\EASTER2--50--12.60.keras\n",
      "202/202 [==============================] - 635s 3s/step - loss: 12.6009 - val_loss: 10.5951\n",
      "Epoch 51/51\n",
      "202/202 [==============================] - 636s 3s/step - loss: 12.5230 - val_loss: 10.4747\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796032c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db319ba-a743-40db-b7cf-e73bc8ef7311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
